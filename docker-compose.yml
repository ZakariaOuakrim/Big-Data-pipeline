version: '3'
services:
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    restart: always
    ports:
      - 9870:9870
      - 9000:9000
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=hadoop-cluster
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    networks:
      - hadoop-network
      
  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    restart: always
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    depends_on:
      - namenode
    networks:
      - hadoop-network
      
  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: resourcemanager
    restart: always
    ports:
      - 8088:8088
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    depends_on:
      - namenode
      - datanode
    networks:
      - hadoop-network
      
  nodemanager:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: nodemanager
    restart: always
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    depends_on:
      - namenode
      - datanode
      - resourcemanager
    networks:
      - hadoop-network
      
  historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
    container_name: historyserver
    restart: always
    ports:
      - 8188:8188
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    depends_on:
      - namenode
      - datanode
      - resourcemanager
    volumes:
      - hadoop_historyserver:/hadoop/yarn/timeline
    networks:
      - hadoop-network
      
  client:
    image: bde2020/hadoop-base:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-client
    entrypoint: ["tail", "-f", "/dev/null"]
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    volumes:
      - ./target:/app
    depends_on:
      - namenode
      - datanode
      - resourcemanager
      - nodemanager
    networks:
      - hadoop-network

  # PostgreSQL database for Hive Metastore and Superset
  postgres:
    image: postgres:13
    container_name: postgres
    restart: always
    ports:
      - 5432:5432
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=metastore
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-db.sql:/docker-entrypoint-initdb.d/init-db.sql
    networks:
      - hadoop-network

  # Hive Metastore
  hive-metastore:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-metastore
    restart: always
    ports:
      - 9083:9083
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - SERVICE_PRECONDITION=namenode:9870 datanode:9864 postgres:5432
    depends_on:
      - namenode
      - datanode
      - postgres
    networks:
      - hadoop-network

  # Hive Server
  hive-server:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-server
    restart: always
    ports:
      - 10000:10000
      - 10002:10002
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - HIVE_CORE_CONF_javax_jdo_option_ConnectionURL=jdbc:postgresql://postgres:5432/metastore
      - SERVICE_PRECONDITION=hive-metastore:9083
    depends_on:
      - hive-metastore
    networks:
      - hadoop-network

  # Redis for Superset caching
  redis:
    image: redis:7-alpine
    container_name: redis
    restart: always
    ports:
      - 6379:6379
    networks:
      - hadoop-network

  # Apache Superset
  superset:
    image: apache/superset:latest
    container_name: superset
    restart: always
    ports:
      - 8089:8088
    environment:
      - SUPERSET_CONFIG_PATH=/app/superset_config.py
      - SUPERSET_SECRET_KEY=your-secret-key-change-this
    volumes:
      - superset_data:/app/superset_home
      - ./superset_config.py:/app/superset_config.py
    depends_on:
      - postgres
      - redis
    networks:
      - hadoop-network
    command: >
      bash -c "
      superset db upgrade &&
      superset fab create-admin --username admin --firstname Admin --lastname User --email admin@superset.com --password admin &&
      superset init &&
      superset run -h 0.0.0.0 -p 8088 --with-threads --reload --debugger
      "
      
networks:
  hadoop-network:
    driver: bridge
    
volumes:
  hadoop_namenode:
  hadoop_datanode:
  hadoop_historyserver:
  postgres_data:
  superset_data: